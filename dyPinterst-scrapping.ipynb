{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urljoin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    \"\"\"Initialize Selenium WebDriver.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run browser in headless mode\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    driver_path = r\"C:\\Users\\Sajid\\Downloads\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\"  # Replace with your ChromeDriver path\n",
    "    service = Service(driver_path)\n",
    "    return webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pinterest_images(search_query, num_images=20):\n",
    "    \"\"\"\n",
    "    Scrape Pinterest images based on a search query.\n",
    "    \n",
    "    Args:\n",
    "        search_query (str): The search term for Pinterest.\n",
    "        num_images (int): Number of images to scrape.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries containing image URLs and filenames.\n",
    "    \"\"\"\n",
    "    # Create URL for Pinterest search\n",
    "    search_url = f\"https://www.pinterest.com/search/pins/?q={search_query.replace(' ', '%20')}\"\n",
    "    driver = setup_driver()\n",
    "    driver.get(search_url)\n",
    "\n",
    "    # Scroll and load images dynamically\n",
    "    image_urls = set()\n",
    "    scroll_pause_time = 2\n",
    "    scroll_count = 0\n",
    "\n",
    "    while len(image_urls) < num_images and scroll_count < 10:\n",
    "        # Scroll down\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(scroll_pause_time)\n",
    "        \n",
    "        # Find all image elements\n",
    "        image_elements = driver.find_elements(By.CSS_SELECTOR, \"img\")\n",
    "        for img in image_elements:\n",
    "            src = img.get_attribute(\"src\")\n",
    "            if src and \"pinimg.com\" in src:\n",
    "                image_urls.add(src)\n",
    "        \n",
    "        scroll_count += 1\n",
    "    \n",
    "    # Quit driver\n",
    "    driver.quit()\n",
    "\n",
    "    # Download images\n",
    "    folder_name = \"pinterest_images\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    data = []\n",
    "    for i, url in enumerate(list(image_urls)[:num_images]):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                filename = f\"{folder_name}/image_{len(os.listdir(folder_name)) + 1}.jpg\"\n",
    "                with open(filename, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                data.append({\"Image URL\": url, \"Filename\": filename})\n",
    "                print(f\"Downloaded: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image {url}: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: pinterest_images/image_201.jpg\n",
      "Downloaded: pinterest_images/image_202.jpg\n",
      "Downloaded: pinterest_images/image_203.jpg\n",
      "Downloaded: pinterest_images/image_204.jpg\n",
      "Downloaded: pinterest_images/image_205.jpg\n",
      "Downloaded: pinterest_images/image_206.jpg\n",
      "Downloaded: pinterest_images/image_207.jpg\n",
      "Downloaded: pinterest_images/image_208.jpg\n",
      "Downloaded: pinterest_images/image_209.jpg\n",
      "Downloaded: pinterest_images/image_210.jpg\n",
      "Downloaded: pinterest_images/image_211.jpg\n",
      "Downloaded: pinterest_images/image_212.jpg\n",
      "Downloaded: pinterest_images/image_213.jpg\n",
      "Downloaded: pinterest_images/image_214.jpg\n",
      "Downloaded: pinterest_images/image_215.jpg\n",
      "Downloaded: pinterest_images/image_216.jpg\n",
      "Downloaded: pinterest_images/image_217.jpg\n",
      "Downloaded: pinterest_images/image_218.jpg\n",
      "Downloaded: pinterest_images/image_219.jpg\n",
      "Downloaded: pinterest_images/image_220.jpg\n",
      "Data saved to pinterest_images.csv\n"
     ]
    }
   ],
   "source": [
    "def save_to_csv(data, filename=\"pinterest_images.csv\"):\n",
    "    \"\"\"\n",
    "    Save image data to a CSV file, appending new data if the file exists.\n",
    "    \n",
    "    Args:\n",
    "        data (list): List of dictionaries containing image data.\n",
    "        filename (str): Name of the output CSV file.\n",
    "    \"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        # Load existing data and append new data\n",
    "        existing_data = pd.read_csv(filename)\n",
    "        new_data = pd.DataFrame(data)\n",
    "        combined_data = pd.concat([existing_data, new_data]).drop_duplicates(subset=[\"Image URL\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        # No existing file, create a new one\n",
    "        combined_data = pd.DataFrame(data)\n",
    "\n",
    "    # Save to CSV\n",
    "    combined_data.to_csv(filename, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    search_term = \"Stractures\"  # Replace with your search term\n",
    "    num_images_to_download = 20  # Specify the number of images to scrape\n",
    "    scraped_data = scrape_pinterest_images(search_term, num_images_to_download)\n",
    "    save_to_csv(scraped_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
